# Design: 语音输入功能技术设计

## Context

系统需要为练习页面的答案输入添加语音识别功能，支持中文、英文两种语言。**重要约束：不使用 Google 或 Apple 的语音识别服务**。DeepSeek API 本身不支持语音识别功能，需要使用 Vosk.js 进行本地离线识别。

## Goals / Non-Goals

### Goals
- 提供流畅的语音输入体验，支持实时语音转文字
- 支持中文（普通话）、英文两种语言识别
- 与现有文本输入功能无缝集成，用户可自由切换
- 提供清晰的录音状态反馈和错误处理
- **不使用 Google/Apple 语音识别服务**（隐私和数据安全考虑）
- 优先考虑本地离线识别方案（保护用户隐私）

### Non-Goals
- 不使用浏览器原生 Speech Recognition API（依赖 Google/Apple 服务）
- 不实现语音情感分析或语音质量评估（仅做转文字）
- 不实现语音回放功能（仅做输入，不做输出）

## Decisions

### Decision 1: 使用 Vosk 进行本地离线语音识别（推荐方案）

**选择**: 使用 Vosk.js 进行本地离线语音识别

**理由**:
- **完全离线**：语音数据不离开用户设备，保护隐私
- **支持所需语言**：支持中文、英文两种语言（满足需求）
- **开源免费**：无需API调用成本
- **模型体积适中**：每种语言模型约50MB，两种语言共约100MB，可接受
- **准确率可接受**：经过训练可达到中等以上准确率
- **符合隐私要求**：数据完全本地处理，不依赖第三方服务
- **DeepSeek不支持**：DeepSeek API 不支持语音转文字功能，无法使用

**技术实现**:
- 使用 Vosk.js（JavaScript包装器）
- 通过 WebAssembly 在浏览器中运行识别模型
- 使用 Web Audio API 进行音频采集
- 模型文件存储在本地，首次使用时下载

**替代方案**:
- **方案2：通过后端调用讯飞语音识别API**
  - 优点：识别准确率高，支持流式识别
  - 缺点：需要后端代理，增加系统复杂度，需要API密钥
  - 适用场景：对准确率要求极高，可以接受后端改动的场景
- **方案3：使用其他第三方服务（百度、Azure等）**
  - 需要后端代理，增加成本和复杂度
  - 不符合本地部署的隐私优先原则

### Decision 2: 前端组件化设计

**选择**: 创建独立的 `VoiceInput` 组件，在 `Practice` 页面中集成

**理由**:
- 组件化设计便于复用和维护
- 封装语音识别逻辑，降低页面组件复杂度
- 便于单独测试和调试

**组件结构**:
```
components/
  └── VoiceInput.tsx          # 语音输入组件
      ├── 录音控制（开始/停止）
      ├── 语言选择器
      ├── 状态显示（录音中、识别中）
      └── 识别结果回调

utils/
  └── speechRecognition.ts    # 语音识别工具函数
      ├── 浏览器兼容性检测
      ├── API封装
      └── 错误处理
```

### Decision 3: 语言识别策略

**选择**: 用户手动选择识别语言，系统根据选择设置API语言参数

**理由**:
- 三种语言差异较大（中文vs英文vs粤语），自动检测准确率低
- 用户明确知道要使用的语言，手动选择更可靠
- 简化实现，避免复杂的语言检测逻辑

**语言映射**:
- 中文（普通话）: `zh-CN`
- 英文: `en-US` 或 `en-GB`

**替代方案**:
- 自动检测语言：准确率低，可能误识别
- 根据题目类别自动选择：不够灵活，用户可能用不同语言回答

### Decision 4: 识别结果处理

**选择**: 识别结果自动填充到文本输入框，支持手动编辑

**理由**:
- 保持与现有文本输入流程一致
- 允许用户修正识别错误
- 支持追加录音（多次录音结果合并）

**交互流程**:
1. 用户点击"语音输入"按钮
2. 选择识别语言（首次使用或切换语言时）
3. 开始录音，显示录音状态
4. 停止录音，开始识别
5. 识别完成后，结果填充到输入框
6. 用户可继续编辑或再次录音

### Decision 5: 浏览器兼容性和模型加载

**选择**: 使用 Vosk.js，支持所有现代浏览器（通过 WebAssembly）

**理由**:
- Vosk.js 基于 WebAssembly，支持所有现代浏览器
- 不依赖浏览器原生API，兼容性更好
- 首次使用时需要下载语言模型（约50MB），后续可缓存

**模型加载策略**:
- 首次使用时提示用户下载语言模型
- 模型文件存储在浏览器 IndexedDB 中，避免重复下载
- 支持按需加载（用户选择语言后再加载对应模型）
- 提供加载进度提示

**降级方案**:
- 如果 WebAssembly 不支持：隐藏语音输入按钮
- 如果模型加载失败：提示用户使用文本输入
- 如果识别失败：允许用户重试或切换回文本输入

## Risks / Trade-offs

### Risk 1: 模型体积和加载时间

**风险**: Vosk 语言模型约50MB，首次加载需要时间

**影响**: 首次使用体验可能较慢，需要等待模型下载

**缓解措施**:
- 提供加载进度提示
- 模型下载后缓存到 IndexedDB，后续无需重新下载
- 支持后台预加载（用户进入练习页面时开始加载）
- 提供"稍后使用"选项，允许用户先使用文本输入

### Risk 2: 识别准确率

**风险**: 本地识别准确率可能低于云端服务，特别是对于口音、噪音环境

**影响**: 识别结果可能需要更多手动修正

**缓解措施**:
- 提供手动编辑功能
- 支持多次录音和追加内容
- 提供识别结果预览，用户确认后再填充
- 如果准确率不满足需求，可考虑切换到方案2（讯飞API）

### Risk 3: 识别准确率

**风险**: 语音识别可能出错，特别是口音、噪音、语速等因素影响

**影响**: 识别结果需要用户手动修正，降低效率

**缓解措施**:
- 提供手动编辑功能
- 支持多次录音和追加内容
- 提供识别结果预览，用户确认后再提交

### Risk 3: WebAssembly 性能

**风险**: 在浏览器中运行语音识别模型可能消耗较多CPU和内存

**影响**: 可能影响页面性能，特别是在低端设备上

**缓解措施**:
- 优化模型加载，使用流式加载减少内存占用
- 提供性能监控，低端设备自动降级到文本输入
- 支持识别过程中暂停/恢复，避免长时间占用资源

### Risk 4: 模型更新和维护

**风险**: Vosk 模型需要定期更新以提升准确率

**影响**: 需要维护模型文件，更新可能影响用户体验

**缓解措施**:
- 模型版本管理，支持增量更新
- 提供模型更新提示（可选）
- 如果模型文件损坏，支持重新下载

## Implementation Details

### 组件API设计

```typescript
interface VoiceInputProps {
  onResult: (text: string) => void;  // 识别结果回调
  onError?: (error: Error) => void;  // 错误回调
  language?: 'zh-CN' | 'en-US';  // 识别语言（中文或英文）
  disabled?: boolean;  // 是否禁用
  onModelLoading?: (progress: number) => void;  // 模型加载进度回调
}

interface VoskConfig {
  modelPath: string;  // 模型文件路径（CDN或本地）
  language: string;  // 识别语言代码
  sampleRate: number;  // 采样率（默认16000）
}
```

### 状态管理

```typescript
type VoiceInputState = 
  | 'idle'           // 空闲
  | 'listening'      // 录音中
  | 'processing'     // 识别中
  | 'completed'      // 识别完成
  | 'error';         // 错误状态
```

### 错误处理

- WebAssembly不支持: 隐藏组件，提示使用文本输入
- 模型加载失败: 显示错误提示，允许重试或使用文本输入
- 麦克风权限拒绝: 提示用户允许麦克风权限
- 识别失败: 显示错误提示，允许重试
- 内存不足: 提示用户关闭其他标签页或使用文本输入

## Migration Plan

### 阶段1: 基础功能实现
1. 创建 `VoiceInput` 组件和工具函数
2. 在 `Practice` 页面集成语音输入
3. 实现基本的录音和识别功能

### 阶段2: 用户体验优化
1. 添加语言选择器
2. 优化状态反馈和错误提示
3. 支持多次录音和结果合并

### 阶段3: 兼容性和测试
1. 测试不同浏览器的兼容性
2. 处理边界情况和错误场景
3. 优化性能和用户体验

### 回滚方案
- 如果功能出现严重问题，可以通过配置开关禁用语音输入
- 保留文本输入作为主要输入方式，不影响核心功能

## Open Questions

1. **模型存储位置**: Vosk 模型文件存储在哪里？
   - **决策**: 
     - 开发环境：存储在 `public/models/` 目录
     - 生产环境：使用 CDN 或本地服务器提供模型文件
     - 浏览器缓存：使用 IndexedDB 缓存已下载的模型

2. **语言支持**: 只需要中文和英文，不需要粤语支持
   - **决策**: 仅实现中文（zh-CN）和英文（en-US）两种语言的识别

3. **识别结果格式**: Vosk 是否自动添加标点符号？
   - **决策**: 
     - Vosk 默认不添加标点，需要后处理
     - 可以集成简单的标点符号添加逻辑（可选）
     - 或者依赖用户手动添加标点

4. **录音时长限制**: 是否需要设置最大录音时长？
   - **决策**: 
     - 不设置硬性限制，但建议用户分段录音（每段不超过60秒）
     - 长时间录音可能影响识别准确率和性能

5. **实时识别 vs 批量识别**: Vosk 支持流式识别还是批量识别？
   - **决策**: 
     - Vosk 支持流式识别，可以实时返回结果
     - 实现实时结果显示，提升用户体验

6. **备选方案**: 如果 Vosk 方案不满足需求，是否实现讯飞API方案？
   - **决策**: 
     - 先实现 Vosk 方案（本地离线，隐私优先）
     - 如果准确率或性能不满足需求，再考虑实现讯飞API方案作为备选
     - 两种方案可以通过配置切换
